# ğŸ§  Retail Insights Assistant  
**GenAI-Powered Conversational Analytics for Retail Data**

## ğŸ“Œ Overview

The Retail Insights Assistant is a GenAI-powered system that enables business users to analyze retail datasets using natural language queries.
It supports:

- Conversational Q&A (e.g., â€œWhich category is underperforming?â€)
- Automated summarization (e.g., â€œSummarize overall stock performanceâ€)
- Follow-up questions with conversation memory
- Schema-aware, safe SQL generation
- Scalable architecture suitable for 100GB+ datasets (design level)

The system combines data engineering, LLM reasoning, and a multi-agent architecture to deliver reliable insights over real-world retail data.

## âœ¨ Key Features

- ğŸ“ Accepts CSV / Excel retail datasets
- ğŸ’¬ ChatGPT-like conversational interface (Streamlit)
- ğŸ§  Multi-agent design:
    - Mode Detection
    - Intent Extraction
    - Data Extraction (SQL)
    - Validation & Reasoning
    - Explanation & Summarization
- ğŸ§¾ Semantic schema generation (automatic, dataset-aware)
- ğŸ›¡ï¸ Safe SQL execution (numeric casting, validation)
- â™»ï¸ Conversation memory for follow-ups
- ğŸ“Š Summarization & Q&A use the same pipeline 

## ğŸ—ï¸ Project Structure
```
retail-insights-assistant/
â”‚
â”œâ”€â”€ app.py                     # Streamlit Chat UI
â”œâ”€â”€ main.py                    # CLI runner (optional)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                       # OpenAI API key
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ loader.py              # CSV / Excel loader
â”‚   â”œâ”€â”€ profiler.py            # Dataset profiling
â”‚   â”œâ”€â”€ semantic_schema.py     # LLM-based schema generation
â”‚   â””â”€â”€ file_detector.py
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ mode_detection_agent.py
â”‚   â”œâ”€â”€ intent_extraction_agent.py
â”‚   â”œâ”€â”€ intent_merge.py
â”‚   â”œâ”€â”€ data_extraction_agent.py
â”‚   â”œâ”€â”€ validation_reasoning_agent.py
â”‚   â”œâ”€â”€ summarization_agent.py
â”‚   â”œâ”€â”€ explanation_agent.py
â”‚   â””â”€â”€ time_followup_resolver.py
â”‚
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ conversation_memory.py
â”‚
â”œâ”€â”€ db/
â”‚   â””â”€â”€ duckdb_conn.py
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ semantic_schema_prompt.txt
â”‚   â””â”€â”€ intent_extraction_prompt.txt
â”‚
â””â”€â”€ data/
    â””â”€â”€ sample_sales.csv
```
## âš™ï¸ Environment Setup

### Clone repository
```
git clone <repo-url>
cd retail-insights-assistant
```

### Create virtual environment
```
python -m venv venv
venv\Scripts\activate
```

### Install dependencies
```
pip install -r requirements.txt
```

## ğŸ”‘ OpenAI API Key

Create a `.env` file:

```
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxx
```

## â–¶ï¸ Run Application

```
streamlit run app.py
```
## ğŸ’¬ Example Questions

- Which category has the highest stock?
- Which SKU is underperforming?
- Show stock distribution by size
- Summarize overall performance

## ğŸ§  How the System Works (High Level)

1. Dataset Profiling
    - Detects numeric vs categorical columns
2. Semantic Schema Generation (LLM)
    - Identifies metrics, dimensions, grain
    - Enforced with rule-based validation
3. Mode Detection
    - Summarization vs Q&A
4. Intent Extraction
    - Converts natural language â†’ structured intent
5. SQL Generation
    - Safe, validated DuckDB queries
6. Business Reasoning
    - Top / bottom / distribution logic
7. LLM Explanation
    - Compressed facts â†’ natural language insights
8. Conversation Memory
    - Enables follow-up questions safely
    
## ğŸ“Š Scalability

While the demo runs locally, the architecture supports scaling via:
- Parquet / Delta Lake storage
- Cloud data lakes (S3, GCS, ADLS)
- Spark / Databricks / BigQuery
- Column pruning & SQL pushdown
- Minimal LLM token usage (facts only)

## ğŸ›¡ï¸Safety & Reliability
- No raw data sent to LLM
- Numeric casting for dirty CSVs
- Feasibility validation (time, metrics)
- Graceful error handling
- Token compression to avoid rate limits

## ğŸ“¸ Demo Evidence (Recommended)

For submission screenshots:

- Dataset uploaded successfully
![alt text](imgs\Datasetupload.png)

- Q&A example
![alt text](imgs\Q&A.png)

- Follow-up question
![alt text](imgs\followup.png)

- Summarization output
![alt text](imgs\Summary.png)

## âš ï¸ Assumptions & Limitations

- Time-based analysis requires a date column
- YoY / QoQ analysis depends on data availability
- Vector search is optional (not required for this assignment)

## ğŸš€ Future Improvements

- Add Streamlit filters & charts
- Integrate vector DB for report similarity
- Deploy on cloud (AWS / GCP / Azure)
- Add role-based access & logging

## âœ… Conclusion
A production-ready GenAI retail analytics assistant.
